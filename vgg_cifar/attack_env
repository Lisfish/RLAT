import torch
import torch.nn as nn
from torchvision import transforms
from torch.utils.data import DataLoader
import numpy as np
from my_models import VGG16  # 确保导入新类
from torchvision import datasets


class AttackEnv:
    def __init__(self, model_path, data_dir, img_size=224, mask_size=16): # VGG通常用224
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.img_size = img_size
        self.mask_size = mask_size
        self.num_grids = img_size // mask_size

        # 1. 加载 VGG-16
        self.model = VGG16().to(self.device)
        # 加载权重
        self.model.load_state_dict(
            torch.load(model_path, map_location=self.device, weights_only=True)
        )
        self.model.eval()

        # 2. 预处理：VGG-16 常用 224x224 分辨率
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize(
                mean=[0.5071, 0.4867, 0.4408],
                std=[0.2675, 0.2565, 0.2761]
            )
        ])

        self.dataset = datasets.CIFAR100(
            root=data_dir,
            train=False,
            download=True,
            transform=self.transform
        )
        self.data_loader = DataLoader(self.dataset, batch_size=1, shuffle=True)
        # 获取类别名称
        self.classes = self.dataset.classes
        self.data_iter = iter(self.data_loader)
        self.mask_noise = torch.randn(3, mask_size, mask_size).to(self.device) * 0.1

    def reset(self):
        try:
            self.current_img, self.label = next(self.data_iter)
        except StopIteration:
            self.data_iter = iter(self.data_loader)
            self.current_img, self.label = next(self.data_iter)

        self.current_img = self.current_img.to(self.device)
        self.label = self.label.to(self.device)
        self.original_img = self.current_img.clone()
        return self.get_state()

    def step(self, action):
        i = action // self.num_grids
        j = action % self.num_grids
        x_min, y_min = i * self.mask_size, j * self.mask_size

        with torch.no_grad():
            self.current_img[:, :, x_min:x_min + self.mask_size, y_min:y_min + self.mask_size] += self.mask_noise
            # 限制像素范围（考虑归一化后的范围）
            self.current_img = torch.clamp(self.current_img, -2.1, 2.7)

            output = self.model(self.current_img)

            # Top-1 预测（用于日志）
            new_pred = torch.argmax(output, dim=1).item()

            # Top-5 预测（用于攻击判定）
            top5_preds = torch.topk(output, k=5, dim=1).indices.squeeze(0)
            true_label = self.label.item()

        l2_dist = torch.norm(self.current_img - self.original_img).item()
        done = (true_label not in top5_preds.tolist())
        reward = 10.0 - l2_dist if done else -0.1 - (l2_dist * 0.01)

        return self.get_state(), reward, done, {
            "l2": l2_dist,
            "pred": new_pred,
            "top5": top5_preds.tolist()
        }

    def get_state(self):
        """为 DQN 提供稳定的特征表示"""
        with torch.no_grad():
            features = self.model.features(self.current_img)
            # 使用 GAP 确保状态维度始终为 512
            gap = torch.nn.functional.adaptive_avg_pool2d(features, (1, 1))
            x = gap.view(gap.size(0), -1)
            return x.squeeze(0) # 返回 512 维向量
